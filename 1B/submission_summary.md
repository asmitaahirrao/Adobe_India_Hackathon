# ğŸ”— Adobe India Hackathon - Round 1B Submission Summary

## ğŸ“Œ Challenge Name: Connecting the Dots Through Docs (Round 1B)

---

## ğŸ“‚ Objective:
To build an intelligent document processing system that extracts the most relevant sections from a set of PDFs based on a given **persona** and **job-to-be-done** (task), and outputs structured insights in a predefined JSON format for multiple groups.

---

## ğŸ› ï¸ Tools & Technologies Used:

| Component          | Details                                           |
|--------------------|---------------------------------------------------|
| ğŸ“„ PDF Parsing     | `PyMuPDF` (`fitz`)                                 |
| ğŸ¤– Embedding Model | `sentence-transformers` - `all-MiniLM-L6-v2`      |
| ğŸ” Similarity      | `cosine similarity` from `sentence-transformers.util` |
| ğŸ§  Ranking         | Relevance-based filtering and similarity scoring  |
| ğŸ³ Container       | Docker with `python:3.10-slim` base                |
| ğŸ Language        | Python 3.10                                        |

---

## ğŸ§  Model Used:

### ğŸ”¸ SentenceTransformer
- **Name:** `all-MiniLM-L6-v2`
- **Purpose:** Convert textual blocks and task queries into semantic embeddings.
- **Similarity Metric:** Cosine similarity for relevance ranking.

---

## ğŸ—ƒï¸ Folder Structure:
```
challenge1b/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                  # ğŸ” Entry point to process all groups
â”‚   â”œâ”€â”€ analyzer.py              # ğŸ” Ranking logic using transformer
â”‚   â”œâ”€â”€ pdf_processor.py         # ğŸ“„ Extracts text blocks from PDFs
â”‚   â”œâ”€â”€ utils.py                 # ğŸ•“ Timestamp generator
â”‚   â””â”€â”€ all-MiniLM-L6-v2/        # ğŸ§  Local sentence-transformer model
â”œâ”€â”€ requirements.txt             # ğŸ“¦ Required Python libraries
â”œâ”€â”€ Dockerfile                   # ğŸ³ Container build definition
â”œâ”€â”€ model_download.py            # ğŸ“¥ Script to download and save model
â”œâ”€â”€ input/                       # ğŸ“‚ Folder containing group-wise PDFs and JSONs
â”œâ”€â”€ output/                      # ğŸ“‚ Generated JSON outputs per group
â””â”€â”€ submission_summary.md        # ğŸ“„ This file
```

---

## ğŸ§ª How to Run (Windows CMD):

1. âœ… **Build Docker Image**  
   From the root directory:
   ```cmd
   docker build -t adobe-round1b .
   ```

2. ğŸš€ **Run Docker & Process All Groups**  
   Ensure your group folders and JSONs are in `app/input/`. Then run:
   ```cmd
   docker run --rm -v "%cd%\app\input:/app/input" -v "%cd%\app\output:/app/output" --network none adobe-round1b
   ```

   This will process **all groups** inside `/app/input/`, and generate corresponding:
   ```
   /app/output/<group_name>/challenge1b_output.json
   ```

---

## ğŸ“ Output Format:

Each group generates:
- `challenge1b_output.json` with:
  - `metadata`: includes input docs, persona, task, timestamp
  - `extracted_sections`: top-10 ranked sections with document and page number
  - `subsection_analysis`: full refined text for those sections

---

## âš™ï¸ Enhancements Implemented:
- âœ… Block-level ranking using semantic similarity
- âœ… JSON validation against expected schema
- âœ… Multi-group batch processing in one command
- âœ… Model loading optimized via local cache
- âœ… Filtered and formatted output aligned with Adobe sample

---

## ğŸ™Œ Team Notes:
This project was designed to be scalable, interpretable, and easily testable with multiple PDF groups. Semantic quality of output has been tuned using domain-aware heuristics and pre-trained multilingual models.
